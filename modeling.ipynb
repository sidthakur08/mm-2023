{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import brier_score_loss, confusion_matrix, classification_report, balanced_accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "- Simple Data\n",
    "    - Logistic Regression\n",
    "        - ~~simple~~\n",
    "        - ~~tuned + cross validation~~\n",
    "    - Gaussian NB\n",
    "        - simple\n",
    "        - cross validation\n",
    "    - Random Forest\n",
    "        - untuned\n",
    "        - tuned\n",
    "    - XGBoost\n",
    "        - untuned\n",
    "        - tuned\n",
    "- Scaled Data\n",
    "    - Logistic Regression\n",
    "        - simple\n",
    "        - cross validation\n",
    "    - Gaussian NB\n",
    "        - simple\n",
    "        - cross validation\n",
    "    - Random Forest\n",
    "        - untuned\n",
    "        - tuned\n",
    "    - XGBoost\n",
    "        - untuned\n",
    "        - tuned\n",
    "- PCA \n",
    "    - Logistic Regression\n",
    "        - simple\n",
    "        - cross validation\n",
    "    - Gaussian NB\n",
    "        - simple\n",
    "        - cross validation\n",
    "    - Random Forest\n",
    "        - untuned\n",
    "        - tuned\n",
    "    - XGBoost\n",
    "        - untuned\n",
    "        - tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_csv('computed_data/reg_avg_data.csv')\n",
    "st1_data = final_data[final_data['Season']<2017]\n",
    "st1_data_x = st1_data.iloc[:,4:-1]\n",
    "st1_data_y = st1_data.iloc[:,-1]\n",
    "st2_data = final_data[final_data['Season']<2023]\n",
    "st2_data_x = st2_data.iloc[:,4:-1]\n",
    "st2_data_y = st2_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'neg_brier_score'\n",
    "\n",
    "#Creating model class so that testing and tuning is easy to run all the different models.\n",
    "class Model_Data:\n",
    "    def __init__(self, model_ud, X, y, scoring='f1'):\n",
    "        self.user_defined_model=model_ud\n",
    "        self.X= X\n",
    "        self.y = y\n",
    "        self.scoring = scoring\n",
    "        \n",
    "    def split(self, test_size):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = test_size)\n",
    "    \n",
    "    '''@staticmethod\n",
    "    def scaledata(X_train, X_test):\n",
    "        scaler = StandardScaler()\n",
    "        idx=X_train.columns.get_loc(\"is_lhb\")\n",
    "        colnames = X_train.columns[0:idx]\n",
    "        features_train= X_train[colnames]\n",
    "        features_test= X_test[colnames]\n",
    "        scaler.fit(features_train)\n",
    "        features_train = scaler.transform(features_train)\n",
    "        X_train[colnames] = features_train\n",
    "        features_test = scaler.transform(features_test)\n",
    "        X_test[colnames] = features_test\n",
    "        return X_train, X_test'''\n",
    "            \n",
    "    def tune(self, params):\n",
    "\n",
    "        cv = KFold(n_splits=3)\n",
    "        self.rand_search = GridSearchCV(estimator=self.user_defined_model, param_grid=params, n_jobs=8, \n",
    "                                         cv=cv, scoring=self.scoring, verbose=2)\n",
    "\n",
    "            \n",
    "        self.rand_search = self.rand_search.fit(self.X_train, self.y_train)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (self.rand_search.best_score_, self.rand_search.best_params_))\n",
    "\n",
    "        means = self.rand_search.cv_results_['mean_test_score']\n",
    "        stds = self.rand_search.cv_results_['std_test_score']\n",
    "        parameters = self.rand_search.cv_results_['params']\n",
    "        for mean, stdev, parameters in zip(means, stds, parameters):\n",
    "            print(\"%f (%f) with: %r\" % (mean, stdev, parameters))\n",
    "            \n",
    "    def tune_comp(self, params):\n",
    "\n",
    "        cv = KFold(n_splits=2)\n",
    "        self.rand_search = GridSearchCV(estimator=self.user_defined_model, param_grid=params, n_jobs=8,\n",
    "                                     cv=cv, scoring=self.scoring, verbose=2)\n",
    "            \n",
    "        self.rand_search = self.rand_search.fit(self.X, self.y)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (self.rand_search.best_score_, self.rand_search.best_params_))\n",
    "\n",
    "        means = self.rand_search.cv_results_['mean_test_score']\n",
    "        stds = self.rand_search.cv_results_['std_test_score']\n",
    "        parameters = self.rand_search.cv_results_['params']\n",
    "        for mean, stdev, parameters in zip(means, stds, parameters):\n",
    "            print(\"%f (%f) with: %r\" % (mean, stdev, parameters))\n",
    "    \n",
    "    def fit(self):\n",
    "        self.user_defined_model.set_params(**self.rand_search.best_params_)\n",
    "        self.user_defined_model = self.user_defined_model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    def fit_comp(self):\n",
    "        self.user_defined_model.set_params(**self.rand_search.best_params_)\n",
    "        self.user_defined_model = self.user_defined_model.fit(self.X, self.y)\n",
    "    \n",
    "    def predict(self, input_value=None):\n",
    "        if input_value == None:\n",
    "            result = self.user_defined_model.predict(self.X_test)\n",
    "        else: \n",
    "            result = self.user_defined_model.predict(np.array([input_value]))\n",
    "        return result\n",
    "\n",
    "    def AccuracyReport(self, predictions, input_value=None):\n",
    "        if input_value == None:\n",
    "            print(confusion_matrix(self.y_test,predictions))\n",
    "            print(classification_report(self.y_test,predictions))\n",
    "            acc2 = balanced_accuracy_score(self.y_test,predictions)\n",
    "            acc3 = brier_score_loss(self.y_test,predictions)\n",
    "            print(acc2)\n",
    "            print(acc3)\n",
    "        else:\n",
    "            print(confusion_matrix(np.array([input_value]),predictions))\n",
    "            print(classification_report(np.array([input_value]),predictions))\n",
    "            acc2 = balanced_accuracy_score(np.array([input_value]),predictions)\n",
    "            acc3 = brier_score_loss(self.y_test,predictions)\n",
    "            print(acc2)\n",
    "\n",
    "params_rand = {\n",
    "    \"learning_rate\"    : [0.1, 0.25, 0.3] ,\n",
    "    \"n_estimators\": [50, 100 , 150],\n",
    "    \"max_depth\"        : [3, 4, 5],\n",
    "    \"min_child_weight\" : [1, 3, 5],\n",
    "    \"colsample_bytree\" : [0.5, 0.7, 0.8 ]\n",
    "}\n",
    "\n",
    "params_logreg =    {\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1200 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m lr \u001b[39m=\u001b[39m Model_Data(LogisticRegression(), st1_data_x, st1_data_y, \u001b[39m'\u001b[39m\u001b[39mneg_brier_score\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m lr\u001b[39m.\u001b[39msplit(test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m lr\u001b[39m.\u001b[39;49mtune(params_logreg)\n\u001b[0;32m      4\u001b[0m lr\u001b[39m.\u001b[39mfit()\n\u001b[0;32m      5\u001b[0m preds \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mpredict()\n",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m, in \u001b[0;36mModel_Data.tune\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m     30\u001b[0m cv \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrand_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_defined_model, param_grid\u001b[39m=\u001b[39mparams, n_jobs\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, \n\u001b[0;32m     32\u001b[0m                                  cv\u001b[39m=\u001b[39mcv, scoring\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrand_search \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrand_search\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_train, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train)\n\u001b[0;32m     36\u001b[0m \u001b[39m# summarize results\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrand_search\u001b[39m.\u001b[39mbest_score_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrand_search\u001b[39m.\u001b[39mbest_params_))\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = Model_Data(LogisticRegression(), st1_data_x, st1_data_y, 'neg_brier_score')\n",
    "lr.split(test_size=0.3)\n",
    "lr.tune(params_logreg)\n",
    "lr.fit()\n",
    "preds = lr.predict()\n",
    "lr.AccuracyReport(preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Tuned + KFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Simple"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
